{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NinVT31dbNPp"
      ],
      "authorship_tag": "ABX9TyPFYeSdjPvUBOjxyC1cqL5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristhianSeverino/Data_Engeerig/blob/En-proceso/Aprende_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Quieres Aprender Pysparküê±‚Äçüë§, con este Notebook lo Lograras**\n",
        "\n",
        "> üê±‚ÄçüëìEste Notebook es creacion de: **Cristhian Calle Severino**.\n",
        "\n",
        "**Si este Notebook te fue de ayuda, me encantaria saberlo**\n",
        "**Diviertete Creando**‚òï\n",
        "\n",
        "*   **Github**: https://github.com/CristhianSeverino\n",
        "*   **Linkedin**: https://www.linkedin.com/in/cristhianandrescalleseverino/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0gDtEq37y6BE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ">Este proyecto **Incluye:**üòé\n",
        "\n",
        "* Creacion de datos sinteticos. Se crea un data set normalizado. este datafrae. simula una tabla de hechos de un esquema estrella o copo de nive. Puedes usar tu creatividad para enriquecerlo.\n",
        "* Para Disfrutar al maximo este Notebook. es indispensable tener conocimientos de:\n",
        "\n",
        "1.   SQL y Python\n",
        "2.   Arquitectura de datos\n",
        "3.   Manipulacion de datos con python\n",
        "\n",
        "\n",
        "* Si no Conoces de SQL y Python pasate por mi linkedin o mi Github. en el repositorio donde encontraste este notebook encontraras dos notebook que te ayudaran a entender la manipulacion de datos con Padas y como ejecutar consuktas con SQL\n"
      ],
      "metadata": {
        "id": "d9T3Em_uuU6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalacci√≥n E Importaci√≥n de Librerias**\n",
        "\n",
        "> verifica la instalaci√≥n, desplegado la celda. despues de ejecutar deberia arrojar un prit de confirmacionüê±‚Äçüëì\n",
        "\n"
      ],
      "metadata": {
        "id": "NinVT31dbNPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker\n",
        "!pip install pandas sqlalchemy mysqlclient faker\n",
        "!pip install ipython-sql==0.5.0 prettytable==3.9.0\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Librerias Instaladas ;)\")\n",
        "print(\"=\"*150)\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "from sqlalchemy import create_engine\n",
        "import numpy as np\n",
        "import os as os\n",
        "import locale\n",
        "\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Librerias Importadas ;)\")\n",
        "print(\"=\"*150)\n",
        "\n",
        "%load_ext sql\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Extensi√≥n sql Cargada ;)\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMxPhG_40Vbd",
        "outputId": "3e24f874-ed41-48b9-e2a7-4dbfe496973d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.8.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.8.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.43)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.2.7.tar.gz (91 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.12/dist-packages (37.8.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Building wheels for collected packages: mysqlclient\n",
            "  Building wheel for mysqlclient (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.2.7-cp312-cp312-linux_x86_64.whl size=129065 sha256=d1455fc223d1e38d969f290cbbfdc4e5ea86e0c3de8efcfe9d7fc19e2440e5fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/95/18/7f176fffd46629e710c04c810b9c4d7d4358fe7c96a7d2306d\n",
            "Successfully built mysqlclient\n",
            "Installing collected packages: mysqlclient\n",
            "Successfully installed mysqlclient-2.2.7\n",
            "Requirement already satisfied: ipython-sql==0.5.0 in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Collecting prettytable==3.9.0\n",
            "  Downloading prettytable-3.9.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from ipython-sql==0.5.0) (7.34.0)\n",
            "Requirement already satisfied: sqlalchemy>=2.0 in /usr/local/lib/python3.12/dist-packages (from ipython-sql==0.5.0) (2.0.43)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.12/dist-packages (from ipython-sql==0.5.0) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from ipython-sql==0.5.0) (1.17.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.12/dist-packages (from ipython-sql==0.5.0) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable==3.9.0) (0.2.13)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=2.0->ipython-sql==0.5.0) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=2.0->ipython-sql==0.5.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-sql==0.5.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->ipython-sql==0.5.0) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->ipython-sql==0.5.0) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->ipython-sql==0.5.0) (0.7.0)\n",
            "Downloading prettytable-3.9.0-py3-none-any.whl (27 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: prettytable, jedi\n",
            "  Attempting uninstall: prettytable\n",
            "    Found existing installation: prettytable 3.16.0\n",
            "    Uninstalling prettytable-3.16.0:\n",
            "      Successfully uninstalled prettytable-3.16.0\n",
            "Successfully installed jedi-0.19.2 prettytable-3.9.0\n",
            "======================================================================================================================================================\n",
            "                                                  Librerias Instaladas ;)\n",
            "======================================================================================================================================================\n",
            "======================================================================================================================================================\n",
            "                                                  Librerias Importadas ;)\n",
            "======================================================================================================================================================\n",
            "======================================================================================================================================================\n",
            "                                                  Extensi√≥n sql Cargada ;)\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creaci√≥n de Datos Sinteticos**\n",
        "\n",
        "  * En las siguientes celdas usaremos una funcion parra crear nuestro dat set sintetico. Emularemos una empresa que distribuye material de osteosintesis a nivel America. con **3 headquarters**. Ubicados en **US**üê±‚Äçüèç, **Chile**üê±‚Äçüëì y **Colombia**üê±‚Äçüíª\n",
        "  * Adaptalas acorde a lo que necesites o quieras crear.**Puedes agrandar los datasets, a tu gusto üòé**.\n",
        "  *Si gustas agregar metricas u otro tipo de datos modifica la cuncion. Tambien puedes cmabiar de tipo de industria. atrevete a Crear y explorarü¶æ.\n",
        "\n",
        "**Diviertete Explorando este Proyecto y creando con el. Prospero d√≠a ‚òï**"
      ],
      "metadata": {
        "id": "Yb5bBp3pbUOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#================================= ¬† Data Set Sintetico ¬† =============================================\n",
        "def generate_synthetic_dataset():\n",
        "    \"\"\"\n",
        "    Esta Funcion Genera un dataset sint√©tico de transacciones de ventas de materiales quir√∫rgicos de osteos√≠ntesis.\n",
        "    Simula ventas por un a√±o (2024) equivalentes a 5 millones de d√≥lares en total.\n",
        "    Sucursales: 5 en ciudades clave de Colombia, Chile y Estados Unidos.\n",
        "    \"\"\"\n",
        "    # Pa√≠ses y ciudades principales. Puedes Modificarl. Explora y crea\n",
        "    countries = {\n",
        "        'Colombia': ['Bogot√°', 'Medell√≠n', 'Cali'],\n",
        "        'Chile': ['Santiago', 'Valpara√≠so', 'Concepci√≥n'],\n",
        "        'Estados Unidos': ['New York', 'Los Angeles', 'Chicago']\n",
        "    }\n",
        "\n",
        "    # Seleccionar 5 sucursales en ciudades clave\n",
        "    branches = [\n",
        "        ('Colombia', 'Bogot√°'),\n",
        "        ('Colombia', 'Medell√≠n'),\n",
        "        ('Chile', 'Santiago'),\n",
        "        ('Estados Unidos', 'New York'),\n",
        "        ('Estados Unidos', 'Los Angeles')\n",
        "    ]\n",
        "\n",
        "    # 10 items ficticios de osteos√≠ntesis\n",
        "    items = [\n",
        "        {'name': 'Titanium Bone Screw 4.5mm', 'stock_code': 'TBS045'},\n",
        "        {'name': 'Locking Compression Plate 4.5mm', 'stock_code': 'LCP045'},\n",
        "        {'name': 'Cortical Screw 3.5mm', 'stock_code': 'CS035'},\n",
        "        {'name': 'DHS Screw 12.5mm', 'stock_code': 'DHSS125'},\n",
        "        {'name': 'Intramedullary Nail 8mm', 'stock_code': 'IMN08'},\n",
        "        {'name': 'Distal Femur Plate', 'stock_code': 'DFP'},\n",
        "        {'name': 'Proximal Humerus Plate', 'stock_code': 'PHP'},\n",
        "        {'name': 'Spinal Pedicle Screw', 'stock_code': 'SPS'},\n",
        "        {'name': 'Bone Graft Substitute', 'stock_code': 'BGS'},\n",
        "        {'name': 'Orthopedic Wire 1.25mm', 'stock_code': 'OW125'}\n",
        "    ]\n",
        "\n",
        "    # Clientes ficticios: 4 por sucursal (total 20 cl√≠nicas)\n",
        "    clients = []\n",
        "    for i, (country, city) in enumerate(branches):\n",
        "        for j in range(4):\n",
        "            client_id = f'CL_{i*4 + j + 1:03d}'\n",
        "            clients.append({'client_id': client_id, 'branch': (country, city)})\n",
        "\n",
        "    # Fechas aleatorias para un a√±o (2024)\n",
        "    start_date = datetime(2024, 1, 1)\n",
        "    end_date = datetime(2024, 12, 31)\n",
        "    dates = [start_date + timedelta(days=random.randint(0, 364)) for _ in range(10000)]  # Pool de fechas\n",
        "\n",
        "    # Precios fijos por item (aleatorios entre 10-1000 USD)\n",
        "    item_prices = {item['stock_code']: np.random.uniform(10, 1000) for item in items}\n",
        "\n",
        "    # Generar datos transaccionales\n",
        "    data = []\n",
        "    sale_id = 1\n",
        "    total_sales = 0\n",
        "    target_sales = 5000000  # 5 millones USD - Puedes Hacer el rango de ventas mayor o meor ;)\n",
        "\n",
        "    while total_sales < target_sales and len(data) < 50000:  # L√≠mite para evitar bucles infinitos --> Ojo con esto. aqui ordenas cuantas ventas queires\n",
        "        # Sucursal aleatoria\n",
        "        country, city = random.choice(branches)\n",
        "        headquarters = f'{city}, {country}'\n",
        "\n",
        "        # Cliente aleatorio de esa sucursal\n",
        "        branch_clients = [c for c in clients if c['branch'] == (country, city)]\n",
        "        client = random.choice(branch_clients)['client_id']\n",
        "\n",
        "        # Item aleatorio\n",
        "        item = random.choice(items)\n",
        "        name_item = item['name']\n",
        "        stock_code = item['stock_code']\n",
        "        price = item_prices[stock_code]\n",
        "\n",
        "        # Cantidad aleatoria (1-50 unidades)\n",
        "        unit = random.randint(1, 50)\n",
        "\n",
        "        # Monto total de precios\n",
        "        amount_prices = price * unit\n",
        "\n",
        "        # Costo por unidad (20-70% del precio)\n",
        "        cost_pct = random.uniform(0.2, 0.7)\n",
        "        cost = price * cost_pct\n",
        "        cost_amount = cost * unit\n",
        "\n",
        "        # Utilidad operativa (monto precios - costo total)\n",
        "        operative_utility = amount_prices - cost_amount\n",
        "\n",
        "        # Fecha aleatoria\n",
        "        date = random.choice(dates).strftime('%Y-%m-%d')\n",
        "\n",
        "        data.append({\n",
        "            'sale_id': sale_id,\n",
        "            'name_item': name_item,\n",
        "            'stock_code': stock_code,\n",
        "            'headquarters': headquarters,\n",
        "            'client_id': client,\n",
        "            'date': date,\n",
        "            'prices': round(price, 2),\n",
        "            'unit': unit,\n",
        "            'amount_prices': round(amount_prices, 2),\n",
        "            'cost': round(cost, 2),\n",
        "            'cost_amount': round(cost_amount, 2),\n",
        "            'operative_utility': round(operative_utility, 2)\n",
        "        })\n",
        "\n",
        "        total_sales += amount_prices\n",
        "        sale_id += 1\n",
        "\n",
        "    # Si se excede el target, ajustar la √∫ltima transacci√≥n proporcionalmente\n",
        "    if total_sales > target_sales:\n",
        "        overshoot = total_sales - target_sales\n",
        "        last_row = data[-1]\n",
        "        trim_factor = 1 - (overshoot / last_row['amount_prices'])\n",
        "        last_row['unit'] *= trim_factor\n",
        "        last_row['unit'] = max(1, round(last_row['unit']))  # M√≠nimo 1 unidad\n",
        "        last_row['amount_prices'] = round(last_row['prices'] * last_row['unit'], 2)\n",
        "        last_row['cost_amount'] = round(last_row['cost'] * last_row['unit'], 2)\n",
        "        last_row['operative_utility'] = round(last_row['amount_prices'] - last_row['cost_amount'], 2)\n",
        "        total_sales = target_sales\n",
        "\n",
        "    # Crear DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.sort_values('date').reset_index(drop=True)  # Ordenar por fecha\n",
        "\n",
        "    print(f\"Dataset generado: {len(df)} transacciones con ventas totales: ${total_sales:,.2f}\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "0bnPS4UZcCkV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejecutar Funciones**"
      ],
      "metadata": {
        "id": "_zc8b3KFVMWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=======================================   Ejecuci√≥n de Funciones    =====================================\n",
        "\n",
        "# 1. Generar los DataFrames con la funci√≥n `generar_esquema_estrella`\n",
        "df= generate_synthetic_dataset()\n",
        "print(\"Iniciando la generaci√≥n de los datos de negocio... üìà\")\n",
        "# 2. Mostrar las primeras filas del DataFrame\n",
        "print(\"=\"*150)\n",
        "print(\"Datos generados exitosamente. üéâ\")\n",
        "print(df.head())\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50 + \"Estadisticas Del DataSet\")\n",
        "print(\"=\"*150)\n",
        "print(df.describe())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV2AF9HCBQWR",
        "outputId": "d85bada5-45d9-480d-81d4-ddf47fb129a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generado: 381 transacciones con ventas totales: $5,000,000.00\n",
            "Iniciando la generaci√≥n de los datos de negocio... üìà\n",
            "======================================================================================================================================================\n",
            "Datos generados exitosamente. üéâ\n",
            "   sale_id                  name_item stock_code                 headquarters  \\\n",
            "0       28       Cortical Screw 3.5mm      CS035  Los Angeles, Estados Unidos   \n",
            "1      356      Bone Graft Substitute        BGS              Santiago, Chile   \n",
            "2      304    Intramedullary Nail 8mm      IMN08              Santiago, Chile   \n",
            "3      220           DHS Screw 12.5mm    DHSS125              Santiago, Chile   \n",
            "4      257  Titanium Bone Screw 4.5mm     TBS045  Los Angeles, Estados Unidos   \n",
            "\n",
            "  client_id       date  prices  unit  amount_prices    cost  cost_amount  \\\n",
            "0    CL_020 2024-01-01   83.65    41        3429.47   24.55      1006.51   \n",
            "1    CL_009 2024-01-02  926.30    29       26862.72  302.94      8785.40   \n",
            "2    CL_009 2024-01-02   22.58    11         248.36    4.61        50.66   \n",
            "3    CL_012 2024-01-03  696.52    49       34129.27  458.60     22471.57   \n",
            "4    CL_018 2024-01-04  899.06    20       17981.26  404.18      8083.65   \n",
            "\n",
            "   operative_utility  \n",
            "0            2422.96  \n",
            "1           18077.32  \n",
            "2             197.70  \n",
            "3           11657.70  \n",
            "4            9897.62  \n",
            "======================================================================================================================================================\n",
            "                                                  Estadisticas Del DataSet\n",
            "======================================================================================================================================================\n",
            "          sale_id                           date      prices        unit  \\\n",
            "count  381.000000                            381  381.000000  381.000000   \n",
            "mean   191.000000  2024-07-01 13:02:21.732283392  508.370682   25.695538   \n",
            "min      1.000000            2024-01-01 00:00:00   22.580000    1.000000   \n",
            "25%     96.000000            2024-03-28 00:00:00   83.650000   14.000000   \n",
            "50%    191.000000            2024-07-11 00:00:00  696.520000   25.000000   \n",
            "75%    286.000000            2024-09-26 00:00:00  845.750000   40.000000   \n",
            "max    381.000000            2024-12-30 00:00:00  926.300000   50.000000   \n",
            "std    110.129469                            NaN  367.492578   14.658093   \n",
            "\n",
            "       amount_prices        cost   cost_amount  operative_utility  \n",
            "count     381.000000  381.000000    381.000000         381.000000  \n",
            "mean    13123.581575  225.920814   5698.269396        7425.312100  \n",
            "min        22.580000    4.530000      8.140000          11.470000  \n",
            "25%      2091.140000   41.610000    847.080000        1056.130000  \n",
            "50%      7858.780000  207.360000   3470.370000        4349.050000  \n",
            "75%     22231.220000  378.200000   9111.660000       11657.700000  \n",
            "max     46315.030000  645.040000  28025.990000       35248.890000  \n",
            "std     13104.534165  185.141539   6073.226759        8053.757847  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('dataset_ventas_sintetico.csv', index=False)"
      ],
      "metadata": {
        "id": "wF25ZzpE0s6S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DIVIERTE CREANDOü§ó**\n",
        "\n",
        "*Si este poyecto te fue de ayuda. pasa por mi linkedin y cuentame como te ayudo. ‚òï*\n",
        "\n",
        "* **linkedink:** https://www.linkedin.com/in/cristhianandrescalleseverino/\n",
        "\n",
        "He dejado Las siguientes celdas para que agregues tus consultas personalizadas, animate a **crear**.\n",
        "\n",
        "***Ser cada d√≠a un 1% mejor es la clave üî•***"
      ],
      "metadata": {
        "id": "bMc31ythgMZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PySpark**\n",
        "##3 keys Questions... Las peguntas del millon de tazas de cafeüê±‚Äçüëì‚òïüê±‚Äçüëì\n",
        "## **¬øQue es?**\n",
        "\n",
        "  Imagina que tienes una monta√±a de datos que analizar. PySpark es la herramienta que te permite procesarla de forma distribuida en miles de computadoras, como si tuvieras un ej√©rcito de robots trabajando para ti, en lugar de un solo robot muy lento.\n",
        "\n",
        "##**¬øPor que deberia aprenderlo?**\n",
        "\n",
        "  Porque el Presente y el futuro son los datos a escala. PySpark te da la habilidad de manejar grandes vol√∫menes de informaci√≥n eficientemente, lo cual es esencial para construir modelos de Machine Learning, pipelines de datos y productos anal√≠ticos que no se ahogan en su propia informaci√≥n.\n",
        "\n",
        "## **¬øQue le suma PySpark a Mis Data-projects o Data Products?**\n",
        "\n",
        "  Le a√±ade velocidad y escalabilidad. PySpark no solo hace que tus proyectos no colapsen al crecer los datos, sino que te permite tomar decisiones basadas en an√°lisis de datos masivos en minutos, en lugar de d√≠as, d√°ndote una ventaja competitiva brutal."
      ],
      "metadata": {
        "id": "s5HQuDx205D_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Primer ejercicio** Importar las librerias necesarias de Pysparküê±‚ÄçüöÄ\n",
        "\n",
        ">\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "\n"
      ],
      "metadata": {
        "id": "j62XDu3i_BXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Librerias Importadas ;)\")\n",
        "print(\"=\"*150)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYg_CLBO-8O9",
        "outputId": "bce80d10-6641-45d7-ea4f-e94e5d3ca5d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "                                                  Librerias Importadas ;)\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Segundo Ejercicio** iniciar Sesi√≥n en Pyspark usaremos el metodo **SparkSession.builder.appName** **.getOrCreate()**\n",
        "\n",
        "\n",
        "> spark = SparkSession.builder.appName(\"Ejercicio\").getOrCreate()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eA6VmZkp_NtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Ejercicio\").getOrCreate()"
      ],
      "metadata": {
        "id": "9cVym0Pn_NMq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Tercer Ejercicio** Crearemos Nuestro DataFrame df_spark.\n",
        "El metodo es similar a crear un dataframe con pandas y cargaremos el data **frame con el csv de los datos generados usando**:\n",
        "\n",
        "\n",
        "> df_spark = spark.read.csv(\"dataset_ventas_sintetico.csv\", header=True, inferSchema=True)\n",
        "\n",
        "> df_spark.show(5)  # Para verificar\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NqO5h8c_Ahq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark = spark.read.csv(\"dataset_ventas_sintetico.csv\", header=True, inferSchema=True)\n",
        "\n",
        "df_spark.show(5) # Para verifica"
      ],
      "metadata": {
        "id": "1bisauNPHqaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df22878-5457-4b6c-d241-2fa8f5e6518b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----------+--------------------+---------+----------+------+----+-------------+------+-----------+-----------------+\n",
            "|sale_id|           name_item|stock_code|        headquarters|client_id|      date|prices|unit|amount_prices|  cost|cost_amount|operative_utility|\n",
            "+-------+--------------------+----------+--------------------+---------+----------+------+----+-------------+------+-----------+-----------------+\n",
            "|     28|Cortical Screw 3.5mm|     CS035|Los Angeles, Esta...|   CL_020|2024-01-01| 83.65|  41|      3429.47| 24.55|    1006.51|          2422.96|\n",
            "|    356|Bone Graft Substi...|       BGS|     Santiago, Chile|   CL_009|2024-01-02| 926.3|  29|     26862.72|302.94|     8785.4|         18077.32|\n",
            "|    304|Intramedullary Na...|     IMN08|     Santiago, Chile|   CL_009|2024-01-02| 22.58|  11|       248.36|  4.61|      50.66|            197.7|\n",
            "|    220|    DHS Screw 12.5mm|   DHSS125|     Santiago, Chile|   CL_012|2024-01-03|696.52|  49|     34129.27| 458.6|   22471.57|          11657.7|\n",
            "|    257|Titanium Bone Scr...|    TBS045|Los Angeles, Esta...|   CL_018|2024-01-04|899.06|  20|     17981.26|404.18|    8083.65|          9897.62|\n",
            "+-------+--------------------+----------+--------------------+---------+----------+------+----+-------------+------+-----------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debes poder ver el Head del Data Frame üòé\n",
        "*  Ten en cuenta: nuestro data frame que usaremos en los siguientes ejericicos se llama: **df_spark**"
      ],
      "metadata": {
        "id": "29ALUN_u2Ny8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Cuarto Ejercicio** Filtrado y Selecci√≥n.\n",
        "Practicar filtrado y selecci√≥n de columnas.\n",
        "Instrucciones: Filtra ventas donde operative_utility > 100 y selecciona sale_id, name_item, operative_utility. Agrupa por name_item y cuenta las ventas.\n",
        "\n",
        ">filtered_df = df.filter(col(\"operative_utility\") > 100).select(\"sale_id\", \"name_item\", \"operative_utility\")\n",
        "\n",
        ">filtered_df.groupBy(\"name_item\").agg(count(\"*\").alias(\"total_sales\")).show()\n",
        "\n",
        ">filtered_df.groupBy(\"name_item\").agg(sum(\"operative_utility\").alias(\"total_operative_utility\")).show()"
      ],
      "metadata": {
        "id": "EMbAbAzhBoz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df_spark.filter(col(\"operative_utility\") > 100).select(\"sale_id\", \"name_item\", \"operative_utility\")\n",
        "\n",
        "filtered_df.groupBy(\"name_item\").agg(count(\"*\").alias(\"total_sales\")).show()\n",
        "filtered_df.groupBy(\"name_item\").agg(sum(\"operative_utility\").alias(\"total_operative_utility\")).show()"
      ],
      "metadata": {
        "id": "cAfoEu4iTG_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503c0315-f9a5-4cc6-f635-de0800152808"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+\n",
            "|           name_item|total_sales|\n",
            "+--------------------+-----------+\n",
            "|Bone Graft Substi...|         45|\n",
            "|Orthopedic Wire 1...|         30|\n",
            "|Locking Compressi...|         33|\n",
            "|  Distal Femur Plate|         44|\n",
            "|Cortical Screw 3.5mm|         40|\n",
            "|Proximal Humerus ...|         33|\n",
            "|Intramedullary Na...|         31|\n",
            "|Spinal Pedicle Screw|         37|\n",
            "|Titanium Bone Scr...|         41|\n",
            "|    DHS Screw 12.5mm|         37|\n",
            "+--------------------+-----------+\n",
            "\n",
            "+--------------------+-----------------------+\n",
            "|           name_item|total_operative_utility|\n",
            "+--------------------+-----------------------+\n",
            "|Bone Graft Substi...|               590470.1|\n",
            "|Orthopedic Wire 1...|               32887.36|\n",
            "|Locking Compressi...|      68097.54999999999|\n",
            "|  Distal Femur Plate|              526726.99|\n",
            "|Cortical Screw 3.5mm|      51045.91999999999|\n",
            "|Proximal Humerus ...|      400037.0499999999|\n",
            "|Intramedullary Na...|     11322.560000000003|\n",
            "|Spinal Pedicle Screw|              196825.43|\n",
            "|Titanium Bone Scr...|              553859.51|\n",
            "|    DHS Screw 12.5mm|              397233.87|\n",
            "+--------------------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Quinto Ejercicio** Agregaciones Complejas.\n",
        "**Domina agregaciones para an√°lisis de negocio.**\n",
        "\n",
        "Instrucciones: Agrupa por headquarters y calcula el promedio de prices, suma de amount_prices y m√°ximo de operative_utility. Ordena por suma descendente.\n",
        "\n",
        ">   agg_df = df_spark.groupBy(\"headquarters\").agg(\n",
        "    avg(\"prices\").alias(\"avg_price\"),\n",
        "    sum(\"amount_prices\").alias(\"total_amount\"),\n",
        "    max(\"operative_utility\").alias(\"max_utility\")\n",
        "      ).orderBy(col(\"total_amount\").desc())\n",
        "      agg_df.show()"
      ],
      "metadata": {
        "id": "qk3qpid9F-mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg_df = df_spark.groupBy(\"headquarters\").agg(\n",
        "    avg(\"prices\").alias(\"avg_price\"),\n",
        "    sum(\"amount_prices\").alias(\"total_amount\"),\n",
        "    max(\"operative_utility\").alias(\"max_utility\")\n",
        ").orderBy(col(\"total_amount\").desc())\n",
        "agg_df.show()"
      ],
      "metadata": {
        "id": "UhAAA3ffTHSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a4b190-d6c9-43b4-8e3b-51d4752e80e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+------------------+-----------+\n",
            "|        headquarters|         avg_price|      total_amount|max_utility|\n",
            "+--------------------+------------------+------------------+-----------+\n",
            "|  Medell√≠n, Colombia| 535.2940449438202|1334456.5999999994|    30703.8|\n",
            "|     Santiago, Chile| 543.6455555555556|1027604.4799999997|   30314.25|\n",
            "|    Bogot√°, Colombia|485.42239436619735| 934485.4399999998|   35248.89|\n",
            "|Los Angeles, Esta...| 500.4960000000001| 926973.6900000001|   32283.14|\n",
            "|New York, Estados...|469.57840579710177| 776564.3700000001|   31852.31|\n",
            "+--------------------+------------------+------------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Sexto Ejercicio** Manejo de Valores Faltantes üëÄ.\n",
        "**Detectar y manejar datos incompletos.**\n",
        "\n",
        "Instrucciones: Identifica nulos en cost y operative_utility, rellena con el promedio de cada columna y elimina duplicados por sale_id.\n",
        "\n",
        "## Manejo de Nulosüê±‚Äçüë§\n",
        "\n",
        "> null_counts = df_spark.select(\n",
        "    sum(col(\"cost\").isNull().cast(\"int\")).alias(\"cost\"),\n",
        "    sum(col(\"operative_utility\").isNull().cast(\"int\")).alias(\"operative_utility\")\n",
        ")\n",
        ">print(\"Los Valores Nulos Detectados Son\")\n",
        "\n",
        ">null_counts.show()\n",
        "\n",
        "## Calcular promedios mean_cost and mean_utility üßÆ\n",
        ">mean_cost = df_spark.select(avg(\"cost\")).collect()[0][0]\n",
        "\n",
        ">mean_utility = df_spark.select(avg(\"operative_utility\")).collect()[0][0]\n",
        "\n",
        ">print(\"=\"*150)\n",
        "\n",
        ">print(f\"Media de 'cost': {mean_cost}\")\n",
        "\n",
        ">print(f\"Media de 'operative_utility': {mean_utility}\")\n",
        "\n",
        ">print(\"=\"*150)\n",
        "\n",
        "## Rellenar nulos y eliminar duplicadosüé´\n",
        "\n",
        "> clean_df = df_spark.fillna({\"cost\": mean_cost, \"operative_utility\": mean_utility}).drop_duplicates([\"sale_id\"])\n",
        "\n",
        ">clean_df.show()\n",
        "\n",
        "\n",
        "**Verifica el print de salida al ejecutar**"
      ],
      "metadata": {
        "id": "IhkyhRwENgMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_counts = df_spark.select(\n",
        "    sum(col(\"cost\").isNull().cast(\"int\")).alias(\"cost\"),\n",
        "    sum(col(\"operative_utility\").isNull().cast(\"int\")).alias(\"operative_utility\")\n",
        ")\n",
        "print(\"Los Valores Nulos Detectados Son\")\n",
        "null_counts.show()\n",
        "\n",
        "# 2. Calcular las medias\n",
        "\n",
        "mean_cost = df_spark.select(avg(\"cost\")).collect()[0][0]\n",
        "mean_utility = df_spark.select(avg(\"operative_utility\")).collect()[0][0]\n",
        "print(\"=\"*150)\n",
        "print(f\"Media de 'cost': {mean_cost}\")\n",
        "print(f\"Media de 'operative_utility': {mean_utility}\")\n",
        "print(\"=\"*150)\n",
        "\n",
        "# 3. Rellenar nulos y eliminar duplicados\n",
        "\n",
        "clean_df = df_spark.fillna({\"cost\": mean_cost, \"operative_utility\": mean_utility}).drop_duplicates([\"sale_id\"])\n",
        "\n",
        "clean_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIk-jp0WGgbw",
        "outputId": "a2465ca4-453c-465b-ec50-64b45656ff59"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los Valores Nulos Detectados Son\n",
            "+----+-----------------+\n",
            "|cost|operative_utility|\n",
            "+----+-----------------+\n",
            "|   0|                0|\n",
            "+----+-----------------+\n",
            "\n",
            "======================================================================================================================================================\n",
            "Media de 'cost': 225.92081364829386\n",
            "Media de 'operative_utility': 7425.312099737535\n",
            "======================================================================================================================================================\n",
            "+-------+--------------------+----------+--------------------+---------+----------+------+----+-------------+------+-----------+-----------------+\n",
            "|sale_id|           name_item|stock_code|        headquarters|client_id|      date|prices|unit|amount_prices|  cost|cost_amount|operative_utility|\n",
            "+-------+--------------------+----------+--------------------+---------+----------+------+----+-------------+------+-----------+-----------------+\n",
            "|      1|Locking Compressi...|    LCP045|Los Angeles, Esta...|   CL_018|2024-04-15|153.14|  32|      4900.42| 102.5|    3280.06|          1620.35|\n",
            "|      2|Proximal Humerus ...|       PHP|New York, Estados...|   CL_013|2024-11-08|845.75|  20|     16915.06|521.95|    10438.9|          6476.16|\n",
            "|      3|    DHS Screw 12.5mm|   DHSS125|Los Angeles, Esta...|   CL_018|2024-05-11|696.52|  23|     16019.86|207.36|    4769.33|         11250.53|\n",
            "|      4|Proximal Humerus ...|       PHP|     Santiago, Chile|   CL_012|2024-05-12|845.75|   5|      4228.76|528.36|     2641.8|          1586.96|\n",
            "|      5|Proximal Humerus ...|       PHP|New York, Estados...|   CL_016|2024-10-15|845.75|   8|      6766.02|538.23|    4305.82|           2460.2|\n",
            "|      6|    DHS Screw 12.5mm|   DHSS125|Los Angeles, Esta...|   CL_019|2024-05-10|696.52|  27|     18805.93| 395.8|   10686.57|          8119.35|\n",
            "|      7|  Distal Femur Plate|       DFP|     Santiago, Chile|   CL_012|2024-10-17|832.77|  14|     11658.83|543.74|    7612.34|          4046.49|\n",
            "|      8|Titanium Bone Scr...|    TBS045|  Medell√≠n, Colombia|   CL_005|2024-05-14|899.06|  41|     36861.59|404.98|   16604.38|         20257.21|\n",
            "|      9|Cortical Screw 3.5mm|     CS035|  Medell√≠n, Colombia|   CL_006|2024-09-16| 83.65|  46|       3847.7| 55.06|    2532.81|          1314.88|\n",
            "|     10|Cortical Screw 3.5mm|     CS035|  Medell√≠n, Colombia|   CL_006|2024-03-02| 83.65|   6|       501.87| 20.89|     125.31|           376.56|\n",
            "|     11|    DHS Screw 12.5mm|   DHSS125|Los Angeles, Esta...|   CL_019|2024-08-13|696.52|  41|     28557.15|258.77|   10609.45|         17947.69|\n",
            "|     12|Locking Compressi...|    LCP045|Los Angeles, Esta...|   CL_019|2024-09-07|153.14|  21|       3215.9|103.32|    2169.65|          1046.25|\n",
            "|     13|Intramedullary Na...|     IMN08|New York, Estados...|   CL_016|2024-05-20| 22.58|  42|       948.28|  6.63|     278.36|           669.92|\n",
            "|     14|Locking Compressi...|    LCP045|     Santiago, Chile|   CL_010|2024-12-01|153.14|  45|      6891.21| 78.26|    3521.79|          3369.42|\n",
            "|     15|Proximal Humerus ...|       PHP|New York, Estados...|   CL_014|2024-05-31|845.75|  26|     21989.57|275.06|    7151.58|          14838.0|\n",
            "|     16|  Distal Femur Plate|       DFP|  Medell√≠n, Colombia|   CL_007|2024-10-06|832.77|  10|      8327.73| 378.4|    3783.97|          4543.77|\n",
            "|     17|Intramedullary Na...|     IMN08|Los Angeles, Esta...|   CL_017|2024-05-29| 22.58|  40|       903.13|  6.34|     253.76|           649.37|\n",
            "|     18|Spinal Pedicle Screw|       SPS|  Medell√≠n, Colombia|   CL_008|2024-08-17|357.22|   5|      1786.09|240.05|    1200.23|           585.85|\n",
            "|     19|Cortical Screw 3.5mm|     CS035|Los Angeles, Esta...|   CL_019|2024-06-16| 83.65|  36|      3011.24| 42.75|    1538.93|          1472.31|\n",
            "|     20|  Distal Femur Plate|       DFP|New York, Estados...|   CL_014|2024-10-24|832.77|  47|     39140.35| 292.5|   13747.52|         25392.82|\n",
            "+-------+--------------------+----------+--------------------+---------+----------+------+----+-------------+------+-----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Septimo Ejercicio** Pyspark SQL para Consultas Complejas üëÄ.\n",
        "**Usar SQL en PySpark para an√°lisis avanzado.**\n",
        "\n",
        "Instrucciones: Identifica nulos en cost y operative_utility, rellena con el promedio de cada columna y elimina duplicados por sale_id.\n",
        "\n",
        "## Creamos la vista(view)üê±‚Äçüë§\n",
        "\n",
        "> df_spark.createOrReplaceTempView(\"view_sales\")\n",
        "\n",
        "## Creamos la Consulta SQL üßÆ\n",
        "sql_df = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        headquarters,\n",
        "        SUM(operative_utility) as total_utility\n",
        "    FROM view_sales\n",
        "    WHERE unit > 10\n",
        "    GROUP BY headquarters\n",
        "    HAVING total_utility > 1000\n",
        "    ORDER BY total_utility DESC\n",
        "\"\"\")\n",
        "\n",
        "## Mostrar el resultadoüíª\n",
        "\n",
        "> sql_df.show()\n",
        "\n",
        "\n",
        "**Verifica el print de salida al ejecutar**"
      ],
      "metadata": {
        "id": "SPQ2tMK_Q-6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.createOrReplaceTempView(\"view_sales\")\n",
        "\n",
        "sql_df = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        headquarters,\n",
        "        SUM(operative_utility) as total_utility\n",
        "    FROM view_sales\n",
        "    WHERE unit > 10\n",
        "    GROUP BY headquarters\n",
        "    HAVING total_utility > 1000\n",
        "    ORDER BY total_utility DESC\n",
        "\"\"\")\n",
        "\n",
        "# Mostrar el resultado\n",
        "sql_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwTAcd0UOOvr",
        "outputId": "1c7a62e0-dd3d-4b7f-faa5-fbe76812285e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+\n",
            "|        headquarters|    total_utility|\n",
            "+--------------------+-----------------+\n",
            "|  Medell√≠n, Colombia|711761.3600000001|\n",
            "|    Bogot√°, Colombia|        547963.71|\n",
            "|     Santiago, Chile|526529.9799999999|\n",
            "|Los Angeles, Esta...|501092.5600000001|\n",
            "|New York, Estados...|434947.8000000001|\n",
            "+--------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Octavo Ejercicio** Fuciones de ventana üëÄ.\n",
        "**Usar window functions para rankings y acumulativos**\n",
        "\n",
        "Instrucciones: Calcula el ranking de ventas por operative_utility dentro de cada headquarters y el total acumulado de amount_prices.\n",
        "\n",
        "## Creamosla consulta spark.sqlüê±‚Äçüêâ\n",
        "\n",
        ">sql_funtion_df = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        *,\n",
        "        RANK() OVER (PARTITION BY headquarters ORDER BY operative_utility DESC) as utility_rank,\n",
        "        SUM(operative_utility) OVER (PARTITION BY headquarters ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as cumulative_utility\n",
        "    FROM view_sales\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "## Mostrar el resultadoüíª\n",
        "\n",
        "> sql_funtion_df.show())\n",
        "\n",
        "\n",
        "**Verifica el print de salida al ejecutar**"
      ],
      "metadata": {
        "id": "CqNs2rXUTQVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql_funtion_df = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        *,\n",
        "        RANK() OVER (PARTITION BY headquarters ORDER BY operative_utility DESC) as utility_rank,\n",
        "        SUM(operative_utility) OVER (PARTITION BY headquarters ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as cumulative_utility\n",
        "    FROM view_sales\n",
        "\"\"\")\n",
        "\n",
        "# Mostrar el resultado\n",
        "sql_funtion_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOq_NL5iSoBK",
        "outputId": "fd53c2e4-32d6-461f-b87a-8bcb9f6881c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----------+----------------+---------+----------+------+----+-------------+------+-----------+-----------------+------------+------------------+\n",
            "|sale_id|           name_item|stock_code|    headquarters|client_id|      date|prices|unit|amount_prices|  cost|cost_amount|operative_utility|utility_rank|cumulative_utility|\n",
            "+-------+--------------------+----------+----------------+---------+----------+------+----+-------------+------+-----------+-----------------+------------+------------------+\n",
            "|    105|Cortical Screw 3.5mm|     CS035|Bogot√°, Colombia|   CL_001|2024-01-05| 83.65|  34|      2843.95|  40.8|    1387.14|          1456.81|          50|           1456.81|\n",
            "|    244|Locking Compressi...|    LCP045|Bogot√°, Colombia|   CL_002|2024-01-15|153.14|  42|       6431.8| 79.94|    3357.32|          3074.48|          43|           4531.29|\n",
            "|    298|Bone Graft Substi...|       BGS|Bogot√°, Colombia|   CL_003|2024-01-18| 926.3|  20|     18526.01|233.93|    4678.51|          13847.5|          15|          18378.79|\n",
            "|    177|Cortical Screw 3.5mm|     CS035|Bogot√°, Colombia|   CL_003|2024-01-24| 83.65|  11|        920.1| 41.26|     453.81|           466.29|          59|          18845.08|\n",
            "|    235|Proximal Humerus ...|       PHP|Bogot√°, Colombia|   CL_002|2024-01-27|845.75|   5|      4228.76|436.13|    2180.65|          2048.12|          46|           20893.2|\n",
            "|    232|Intramedullary Na...|     IMN08|Bogot√°, Colombia|   CL_002|2024-02-06| 22.58|  18|       406.41|  6.75|     121.42|           284.99|          63|21178.190000000002|\n",
            "|     61|Bone Graft Substi...|       BGS|Bogot√°, Colombia|   CL_004|2024-02-17| 926.3|  22|     20378.61|325.23|    7155.15|         13223.47|          16|          34401.66|\n",
            "|    139|Bone Graft Substi...|       BGS|Bogot√°, Colombia|   CL_002|2024-02-18| 926.3|  48|     44462.43|191.95|    9213.55|         35248.89|           1|          69650.55|\n",
            "|    197|    DHS Screw 12.5mm|   DHSS125|Bogot√°, Colombia|   CL_003|2024-02-21|696.52|  39|     27164.12|363.92|   14192.69|         12971.43|          17| 82621.98000000001|\n",
            "|    300|    DHS Screw 12.5mm|   DHSS125|Bogot√°, Colombia|   CL_003|2024-02-26|696.52|  15|     10447.74|296.95|    4454.29|          5993.45|          31| 88615.43000000001|\n",
            "|    319|Intramedullary Na...|     IMN08|Bogot√°, Colombia|   CL_004|2024-02-27| 22.58|  20|       451.56|  8.69|      173.8|           277.77|          64| 88893.20000000001|\n",
            "|    368|  Distal Femur Plate|       DFP|Bogot√°, Colombia|   CL_003|2024-03-05|832.77|  19|     15822.69|456.82|    8679.54|          7143.15|          26|          96036.35|\n",
            "|    362|Spinal Pedicle Screw|       SPS|Bogot√°, Colombia|   CL_001|2024-03-05|357.22|  44|     15717.55|211.04|    9285.96|          6431.59|          30|         102467.94|\n",
            "|     44|  Distal Femur Plate|       DFP|Bogot√°, Colombia|   CL_002|2024-03-10|832.77|  41|     34143.71|398.32|   16331.09|         17812.62|          11|         120280.56|\n",
            "|    268|    DHS Screw 12.5mm|   DHSS125|Bogot√°, Colombia|   CL_003|2024-03-12|696.52|   9|      6268.64|213.29|     1919.6|          4349.05|          37|         124629.61|\n",
            "|    166|Intramedullary Na...|     IMN08|Bogot√°, Colombia|   CL_004|2024-03-12| 22.58|  35|       790.24|   6.1|     213.65|           576.59|          56|          125206.2|\n",
            "|    191|Locking Compressi...|    LCP045|Bogot√°, Colombia|   CL_001|2024-03-12|153.14|   3|       459.41| 84.69|     254.07|           205.35|          69|         125411.55|\n",
            "|    203|Bone Graft Substi...|       BGS|Bogot√°, Colombia|   CL_002|2024-03-15| 926.3|  46|     42609.83|245.76|   11305.17|         31304.66|           2|         156716.21|\n",
            "|    314|Cortical Screw 3.5mm|     CS035|Bogot√°, Colombia|   CL_004|2024-03-17| 83.65|  25|      2091.14| 27.39|     684.75|          1406.39|          52|          158122.6|\n",
            "|     31|  Distal Femur Plate|       DFP|Bogot√°, Colombia|   CL_001|2024-03-20|832.77|  16|     13324.37|358.09|    5729.46|          7594.91|          23|         165717.51|\n",
            "+-------+--------------------+----------+----------------+---------+----------+------+----+-------------+------+-----------+-----------------+------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Noveo Ejercicio** An√°lisis de Series de Tiempo con Funciones de Ventana (Window Functions) üëÄ.\n",
        "**Problema:**\n",
        "\n",
        "Problema: Un analista de negocio te pide calcular la utilidad operativa promedio m√≥vil de los √∫ltimos 7 d√≠as para cada headquarters de la empresa. Esto ayudar√° a identificar tendencias recientes en la rentabilidad.\n",
        "### Gu√≠a:\n",
        "\n",
        "* Aseg√∫rate de que la columna date tenga el formato correcto (por ejemplo, DateType).\n",
        "\n",
        "* Define una funci√≥n de ventana que particione los datos por headquarters y ordene por date.\n",
        "\n",
        "* Aplica un rango de ventana de 7 d√≠as (rowsBetween(-7, 0)) para incluir el d√≠a actual y los 7 d√≠as anteriores.\n",
        "\n",
        "* Calcula el promedio (avg) de la columna operative_utility dentro de cada ventana y crea una nueva columna con el resultado.\n",
        "\n",
        "## **Define la Ventanaüê±‚Äçüëì**\n",
        "\n",
        ">df_spark = df_spark.withColumn(\"date\", F.to_date(\"date\"))\n",
        ">windowSpec = Window.partitionBy(\"headquarters\").orderBy(\"date\").rowsBetween(-7, 0)\n",
        "\n",
        "## **Calcula la utilidad promedio movilüê±‚Äçüêâ**\n",
        "\n",
        "df_spark_with_ma = df_spark.withColumn(\n",
        "    \"rolling_avg_utility_7d\",\n",
        "    F.avg(\"operative_utility\").over(windowSpec)\n",
        ")\n",
        "\n",
        "\n",
        "## **Mostrar el resultadoüíª**\n",
        "\n",
        "> df_spark_with_ma.select(\"date\", \"headquarters\", \"operative_utility\", \"rolling_avg_utility_7d\").show(truncate=False)\n",
        "\n",
        "\n",
        "**Verifica el print de salida al ejecutar**"
      ],
      "metadata": {
        "id": "zr15r3YZVMLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_spark = df_spark.withColumn(\"date\", F.to_date(\"date\"))\n",
        "\n",
        "windowSpec = Window.partitionBy(\"headquarters\").orderBy(\"date\").rowsBetween(-7, 0)\n",
        "\n",
        "\n",
        "df_spark_with_ma = df_spark.withColumn(\n",
        "    \"rolling_avg_utility_7d\",\n",
        "    F.avg(\"operative_utility\").over(windowSpec)\n",
        ")\n",
        "\n",
        "df_spark_with_ma.select(\"date\", \"headquarters\", \"operative_utility\", \"rolling_avg_utility_7d\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i39UjQ1HTip4",
        "outputId": "8926e428-8e3d-410c-8bcb-057eca53e936"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------+-----------------+----------------------+\n",
            "|date      |headquarters    |operative_utility|rolling_avg_utility_7d|\n",
            "+----------+----------------+-----------------+----------------------+\n",
            "|2024-01-05|Bogot√°, Colombia|1456.81          |1456.81               |\n",
            "|2024-01-15|Bogot√°, Colombia|3074.48          |2265.645              |\n",
            "|2024-01-18|Bogot√°, Colombia|13847.5          |6126.263333333333     |\n",
            "|2024-01-24|Bogot√°, Colombia|466.29           |4711.27               |\n",
            "|2024-01-27|Bogot√°, Colombia|2048.12          |4178.64               |\n",
            "|2024-02-06|Bogot√°, Colombia|284.99           |3529.6983333333337    |\n",
            "|2024-02-17|Bogot√°, Colombia|13223.47         |4914.522857142858     |\n",
            "|2024-02-18|Bogot√°, Colombia|35248.89         |8706.31875            |\n",
            "|2024-02-21|Bogot√°, Colombia|12971.43         |10145.646249999998    |\n",
            "|2024-02-26|Bogot√°, Colombia|5993.45          |10510.5175            |\n",
            "|2024-02-27|Bogot√°, Colombia|277.77           |8814.30125            |\n",
            "|2024-03-05|Bogot√°, Colombia|6431.59          |9559.96375            |\n",
            "|2024-03-05|Bogot√°, Colombia|7143.15          |10196.842499999999    |\n",
            "|2024-03-10|Bogot√°, Colombia|17812.62         |12387.79625           |\n",
            "|2024-03-12|Bogot√°, Colombia|576.59           |10806.936249999997    |\n",
            "|2024-03-12|Bogot√°, Colombia|205.35           |6426.493749999999     |\n",
            "|2024-03-12|Bogot√°, Colombia|4349.05          |5348.69625            |\n",
            "|2024-03-15|Bogot√°, Colombia|31304.66         |8512.5975             |\n",
            "|2024-03-17|Bogot√°, Colombia|1406.39          |8653.675              |\n",
            "|2024-03-20|Bogot√°, Colombia|375.99           |7896.724999999999     |\n",
            "+----------+----------------+-----------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________\n",
        "# **Decimo Ejercicio** An√°lisis de Utilidad por Sede y MesüëÄüèõ.\n",
        "**Problema:**\n",
        "\n",
        "Problema: Un stakeholder strategico, te pide calcular la utilidad operativa por sede y mes. Ademas agrega que seria de gran valor que se filtrara previamente por el top 5 de productos.\n",
        "\n",
        "### Gu√≠a:\n",
        "\n",
        "* Filtrado por A√±o: Mant√©n el filtro inicial para procesar solo los datos del a√±o 2024.\n",
        "\n",
        "* Extracci√≥n del Mes: Usa la funci√≥n integrada de Spark F.month() para extraer el mes de la columna date. Esto crear√° una nueva columna o se usar√° directamente en el groupBy.\n",
        "\n",
        "* Agregaci√≥n por Granularidad: Agrupa tus datos por las columnas headquarters, month y name_item para calcular la suma de la operative_utility a nivel mensual por producto y sede.\n",
        "\n",
        "* Funci√≥n de Ventana: Redefine la Window Spec para que las particiones se realicen por la combinaci√≥n de headquarters y month. Esto asegura que el ranking de los productos se reinicie y se calcule de forma independiente para cada mes y sede.\n",
        "\n",
        "* Filtro Final: Filtra el DataFrame resultante para mantener solo los registros con un rank igual o menor a 5.\n",
        "\n",
        "\n",
        "\n",
        "## **Filtrar por a√±o objetivo en este caso 2024üê±‚Äçüëì**\n",
        "\n",
        ">df_2024 = df_spark.filter(F.year(F.col(\"date\")) == 2024)\n",
        "\n",
        "## **Agrupa y calcula la utilidad total por sede, mes y productoüê±‚Äçüêâ**\n",
        "\n",
        ">df_profitability = df_2024.groupBy(\"headquarters\", F.month(F.col(\"date\")).alias(\"month\"), \"name_item\") \\\n",
        "                         .agg(F.sum(\"operative_utility\").alias(\"total_utility\"))\n",
        "\n",
        "\n",
        "## **Define y  particiona por 'headquarters' y 'month' la ventana. Para una clasificaci√≥n mensuaüíª**\n",
        "\n",
        "> windowSpec = Window.partitionBy(\"headquarters\", \"month\").orderBy(F.desc(\"total_utility\"))\n",
        "\n",
        "## **Aplica la funci√≥n de clasificaci√≥nüìã**\n",
        ">df_ranked = df_profitability.withColumn(\"rank\", F.rank().over(windowSpec))\n",
        "\n",
        "## **Filtra para obtener los 5 productos m√°s rentables por sede y mesüß≠**\n",
        ">df_top_5_monthly = df_ranked.filter(F.col(\"rank\") <= 5)\n",
        "\n",
        "## **Muestra el resultado‚òï**\n",
        ">df_top_5_monthly.show(truncate=False)*\n",
        "\n",
        "## **Opcional guardar en formato parquetüíæ**\n",
        ">df_top_5_monthly.write.partitionBy(\"headquarters\", \"month\").parquet(\"ruta/a/datos_optimizados_mensuales\")\n",
        "\n",
        "**Verifica el print de salida al ejecutar**"
      ],
      "metadata": {
        "id": "T6ROB9eSXME-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2024 = df_spark.filter(F.year(F.col(\"date\")) == 2024)\n",
        "\n",
        "\n",
        "df_profitability = df_2024.groupBy(\"headquarters\", F.month(F.col(\"date\")).alias(\"month\"), \"name_item\") \\\n",
        "                         .agg(F.sum(\"operative_utility\").alias(\"total_utility\"))\n",
        "\n",
        "\n",
        "windowSpec = Window.partitionBy(\"headquarters\", \"month\").orderBy(F.desc(\"total_utility\"))\n",
        "\n",
        "\n",
        "df_ranked = df_profitability.withColumn(\"rank\", F.rank().over(windowSpec))\n",
        "\n",
        "\n",
        "df_top_5_monthly = df_ranked.filter(F.col(\"rank\") <= 5)\n",
        "\n",
        "df_top_5_monthly.show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIDs06PoV1TA",
        "outputId": "7dcadd1c-7e96-4acd-de4f-0d2a1f332b50"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+-------------------------------+------------------+----+\n",
            "|headquarters    |month|name_item                      |total_utility     |rank|\n",
            "+----------------+-----+-------------------------------+------------------+----+\n",
            "|Bogot√°, Colombia|1    |Bone Graft Substitute          |13847.5           |1   |\n",
            "|Bogot√°, Colombia|1    |Locking Compression Plate 4.5mm|3074.48           |2   |\n",
            "|Bogot√°, Colombia|1    |Proximal Humerus Plate         |2048.12           |3   |\n",
            "|Bogot√°, Colombia|1    |Cortical Screw 3.5mm           |1923.1            |4   |\n",
            "|Bogot√°, Colombia|2    |Bone Graft Substitute          |48472.36          |1   |\n",
            "|Bogot√°, Colombia|2    |DHS Screw 12.5mm               |18964.88          |2   |\n",
            "|Bogot√°, Colombia|2    |Intramedullary Nail 8mm        |562.76            |3   |\n",
            "|Bogot√°, Colombia|3    |Distal Femur Plate             |32550.679999999997|1   |\n",
            "|Bogot√°, Colombia|3    |Bone Graft Substitute          |31304.66          |2   |\n",
            "|Bogot√°, Colombia|3    |DHS Screw 12.5mm               |24580.489999999998|3   |\n",
            "|Bogot√°, Colombia|3    |Spinal Pedicle Screw           |6431.59           |4   |\n",
            "|Bogot√°, Colombia|3    |Cortical Screw 3.5mm           |3368.49           |5   |\n",
            "|Bogot√°, Colombia|4    |Spinal Pedicle Screw           |17284.95          |1   |\n",
            "|Bogot√°, Colombia|4    |Distal Femur Plate             |3804.24           |2   |\n",
            "|Bogot√°, Colombia|5    |Distal Femur Plate             |52082.17          |1   |\n",
            "|Bogot√°, Colombia|5    |Locking Compression Plate 4.5mm|3539.16           |2   |\n",
            "|Bogot√°, Colombia|6    |Distal Femur Plate             |20376.18          |1   |\n",
            "|Bogot√°, Colombia|6    |Bone Graft Substitute          |13253.38          |2   |\n",
            "|Bogot√°, Colombia|6    |Orthopedic Wire 1.25mm         |2009.92           |3   |\n",
            "|Bogot√°, Colombia|6    |Cortical Screw 3.5mm           |1254.0            |4   |\n",
            "+----------------+-----+-------------------------------+------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DIVIERTE CREANDOü§ó**\n",
        "\n",
        "*Si este poyecto te fue de ayuda. pasa por mi linkedin y cuentame como te ayudo. ‚òï*\n",
        "\n",
        "* **linkedink:** https://www.linkedin.com/in/cristhianandrescalleseverino/\n",
        "\n",
        "He dejado Las siguientes celdas para que agregues tus consultas personalizadas, animate a **crear**.\n",
        "\n",
        "***Ser cada d√≠a un 1% mejor es la clave üî•***\n",
        "\n",
        ">Respositorio donde encontraras mas Recursos de aprendizaje: https://github.com/CristhianSeverino/Data_Engeerig.git\n"
      ],
      "metadata": {
        "id": "7tskZEb2abpN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qB4Yu316ahYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}